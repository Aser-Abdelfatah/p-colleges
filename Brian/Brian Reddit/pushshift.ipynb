{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the subreddit you want to collect posts from\n",
    "subreddit = \"usc\"\n",
    "\n",
    "# Set the Pushshift API endpoint for submissions\n",
    "submission_url = \"https://api.pushshift.io/reddit/search/submission/\"\n",
    "\n",
    "# Set the parameters for the API request\n",
    "params = {\"subreddit\": subreddit, \"size\": 10}\n",
    "\n",
    "# Make the API request for submissions\n",
    "submission_response = requests.get(submission_url, params=params)\n",
    "submission_data = submission_response.json()\n",
    "\n",
    "# Create a list to store the post data\n",
    "post_data = []\n",
    "\n",
    "# Loop through each submission and get its comments\n",
    "for submission in submission_data[\"data\"]:\n",
    "    # Get the comments for the submission\n",
    "    comment_url = f\"https://api.pushshift.io/reddit/comment/search?link_id={submission['id']}&limit=10\"\n",
    "    comment_response = requests.get(comment_url)\n",
    "    comment_data = comment_response.json()\n",
    "\n",
    "    # Check if the comment data is empty\n",
    "    if \"data\" not in comment_data:\n",
    "        comments = []\n",
    "    else:\n",
    "        comments = [comment[\"body\"] for comment in comment_data[\"data\"]]\n",
    "\n",
    "    # Add the submission and its comments to the post data list\n",
    "    post_data.append({\n",
    "        \"title\": submission[\"title\"],\n",
    "        \"content\": submission.get(\"selftext\", \"\"),\n",
    "        \"created_utc\": submission[\"created_utc\"],\n",
    "        \"comments\": comments\n",
    "    })\n",
    "\n",
    "# Sort the post data by the timestamp of the submission\n",
    "post_data_sorted = sorted(post_data, key=lambda x: x[\"created_utc\"])\n",
    "\n",
    "# Create a file to store the output\n",
    "output_file = open(f\"{subreddit}.txt\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "# Loop through each post and write the title, content, and comments to the output file\n",
    "for post in post_data_sorted:\n",
    "    output_file.write(post[\"title\"] + \"\\n\")\n",
    "    output_file.write(post[\"content\"] + \"\\n\")\n",
    "    for comment in post[\"comments\"]:\n",
    "        output_file.write(comment + \"\\n\")\n",
    "\n",
    "# Close the output file\n",
    "output_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "institution = 'ucla'\n",
    "size = 1000\n",
    "\n",
    "url = f\"https://api.pushshift.io/reddit/search/submission?subreddit={institution}&size={size}\"\n",
    "response = requests.get(url)\n",
    "\n",
    "data = json.loads(response.text)\n",
    "posts = data['data']\n",
    "\n",
    "with open('ucla_posts.txt', 'w', encoding='utf-8') as f:\n",
    "    for post in posts:\n",
    "        f.write(post['title'] + '\\n')\n",
    "        selftext = post['selftext'].replace('\\n', ' ')\n",
    "        f.write(selftext + '\\n\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "endpoint = \"https://api.pushshift.io/reddit/comment/search/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(post_id):\n",
    "    # define query parameters\n",
    "    params = {\n",
    "        \"link_id\": post_id,\n",
    "        \"fields\": \"body\"\n",
    "    }\n",
    "\n",
    "    # make API request\n",
    "    response = requests.get(endpoint, params=params)\n",
    "\n",
    "    # parse response for comments\n",
    "    comments = []\n",
    "    if response.ok:\n",
    "        print(\"yay!\")\n",
    "        data = response.json()[\"data\"]\n",
    "        print(data)\n",
    "        for comment in data:\n",
    "            comments.append(comment[\"body\"])\n",
    "\n",
    "    return comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay!\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "post_id = \"yf1fd6\"\n",
    "comments = get_comments(post_id)\n",
    "print(comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51923b56f38a5b3424ee861e1200c08869906ff2215aafed0340f54392de6f99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
